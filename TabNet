import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.model_selection import KFold, StratifiedKFold
from pytorch_tabnet.tab_model import TabNetRegressor
import torch
import warnings
from tqdm import tqdm
import optuna
import joblib
from datetime import datetime

warnings.filterwarnings('ignore')

# 创建输出目录
output_dir = 'D:\\PY\\TabNET精调'
os.makedirs(output_dir, exist_ok=True)

# 设置随机种子
seed = 42
np.random.seed(seed)
torch.manual_seed(seed)

# 加载数据
print("加载数据...")
train_data = pd.read_excel('D:\\PY\\train.xlsx')
validation_data = pd.read_excel('D:\\PY\\validation.xlsx')
test_data = pd.read_excel('D:\\PY\\test.xlsx')

# 定义特征和目标变量
features = ["TA", "RH", "P", "SP", "SD", "ATM", "PAR", "TS", "shallow_SWC", "deep_SWC"]
target = "NEP"


# 数据预处理函数
def preprocess_data(df):
    # 提取特征和目标
    X = df[features].values
    y = df[target].values
    # 将目标变量reshape为2D格式 (n_samples, 1)
    y = y.reshape(-1, 1)
    return X, y


# 归一化处理
print("数据归一化处理...")
scaler = StandardScaler()
X_train, y_train = preprocess_data(train_data)
X_val, y_val = preprocess_data(validation_data)
X_test, y_test = preprocess_data(test_data)

X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)


# 评估函数
def evaluate_model(model, X, y, dataset_name):
    y_pred = model.predict(X)
    # 确保y和y_pred都是一维数组用于评估指标计算
    y_flat = y.ravel()
    y_pred_flat = y_pred.ravel() if y_pred.ndim > 1 else y_pred

    r2 = r2_score(y_flat, y_pred_flat)
    mae = mean_absolute_error(y_flat, y_pred_flat)
    mse = mean_squared_error(y_flat, y_pred_flat)
    rmse = np.sqrt(mse)

    print(f"{dataset_name} 评估结果:")
    print(f"R² Score: {r2:.4f}")
    print(f"MAE: {mae:.4f}")
    print(f"MSE: {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print("----------------------------")

    return {
        "dataset": dataset_name,
        "r2": r2,
        "mae": mae,
        "mse": mse,
        "rmse": rmse,
        "y_true": y_flat,
        "y_pred": y_pred_flat
    }


# 网格搜索的最优参数（假设这是您已经得到的结果）
best_params_grid = {
    'n_d': 32,  # 假设这是您的网格搜索得到的最优值
    'n_steps': 5,
    'gamma': 1.3,
    'n_independent': 2,
    'n_shared': 2,
    'learning_rate': 0.02
}

# 保存网格搜索结果
grid_search_results = pd.DataFrame([best_params_grid])
grid_search_results.to_excel(os.path.join(output_dir, 'tabnet_grid_search_best_params.xlsx'), index=False)
print(f"网格搜索最优参数已保存到 {os.path.join(output_dir, 'tabnet_grid_search_best_params.xlsx')}")

# 使用Optuna进行精细调参
print("\n开始使用Optuna进行精细调参...")


# 定义目标函数
def objective(trial):
    # 基于网格搜索结果定义参数搜索空间
    params = {
        'n_d': trial.suggest_int('n_d', max(8, best_params_grid['n_d'] - 8), best_params_grid['n_d'] + 8, 4),
        'n_steps': trial.suggest_int('n_steps', max(3, best_params_grid['n_steps'] - 2),
                                     best_params_grid['n_steps'] + 2),
        'gamma': trial.suggest_float('gamma', max(0.8, best_params_grid['gamma'] - 0.3),
                                     best_params_grid['gamma'] + 0.3, step=0.1),
        'n_independent': trial.suggest_int('n_independent', max(1, best_params_grid['n_independent'] - 1),
                                           best_params_grid['n_independent'] + 1),
        'n_shared': trial.suggest_int('n_shared', max(1, best_params_grid['n_shared'] - 1),
                                      best_params_grid['n_shared'] + 1),
        'learning_rate': trial.suggest_float('learning_rate', max(0.005, best_params_grid['learning_rate'] - 0.015),
                                             best_params_grid['learning_rate'] + 0.015, step=0.005),
        'momentum': trial.suggest_float('momentum', 0.01, 0.4, step=0.01),
        'lambda_sparse': trial.suggest_float('lambda_sparse', 0.0001, 0.001, log=True),
        'batch_size': trial.suggest_categorical('batch_size', [512, 1024, 2048]),
        'virtual_batch_size': trial.suggest_categorical('virtual_batch_size', [64, 128, 256]),
        'max_epochs': trial.suggest_int('max_epochs', 100, 300, 50),
        'patience': trial.suggest_int('patience', 10, 30, 5),
        'clip_value': trial.suggest_float('clip_value', 0.5, 2.0, step=0.1),
        'dropout': trial.suggest_float('dropout', 0.0, 0.5, step=0.1),
    }

    # 五折交叉验证
    kf = KFold(n_splits=5, shuffle=True, random_state=seed)
    cv_scores = []

    for train_idx, val_idx in kf.split(X_train_scaled):
        X_cv_train, X_cv_val = X_train_scaled[train_idx], X_train_scaled[val_idx]
        y_cv_train, y_cv_val = y_train[train_idx], y_train[val_idx]

        # 创建模型
        model = TabNetRegressor(
            n_d=params['n_d'],
            n_steps=params['n_steps'],
            gamma=params['gamma'],
            n_independent=params['n_independent'],
            n_shared=params['n_shared'],
            lambda_sparse=params['lambda_sparse'],
            momentum=params['momentum'],
            optimizer_fn=torch.optim.Adam,
            optimizer_params=dict(lr=params['learning_rate']),
            scheduler_params={"step_size": 10, "gamma": 0.9},
            scheduler_fn=torch.optim.lr_scheduler.StepLR,
            mask_type='entmax',
            clip_value=params['clip_value'],
            verbose=0
        )

        # 移除自定义的EarlyStoppingCallback类和实例化代码

        # 训练模型 - 使用内置早停机制
        model.fit(
            X_cv_train, y_cv_train,
            eval_set=[(X_cv_val, y_cv_val)],
            max_epochs=params['max_epochs'],
            patience=params['patience'],  # 使用内置早停
            batch_size=params['batch_size'],
            virtual_batch_size=params['virtual_batch_size'],
            eval_metric=['rmse'],
            drop_last=True
            # 移除callbacks参数
        )

        # 评估模型
        y_pred = model.predict(X_cv_val)
        y_cv_val_flat = y_cv_val.ravel()
        y_pred_flat = y_pred.ravel() if y_pred.ndim > 1 else y_pred
        score = r2_score(y_cv_val_flat, y_pred_flat)
        cv_scores.append(score)

    # 返回平均R²分数
    mean_score = np.mean(cv_scores)
    return mean_score


# 创建Optuna研究
study = optuna.create_study(direction='maximize', study_name='tabnet_optimization')
study.optimize(objective, n_trials=200, show_progress_bar=True)

# 获取最佳参数
best_params_optuna = study.best_params
print(f"\nOptuna最佳参数: {best_params_optuna}")
print(f"最佳R²分数: {study.best_value:.4f}")

# 保存Optuna优化结果
optuna_results = pd.DataFrame([best_params_optuna])
optuna_results['best_r2'] = study.best_value
optuna_results.to_excel(os.path.join(output_dir, 'tabnet_optuna_best_params.xlsx'), index=False)
print(f"Optuna最优参数已保存到 {os.path.join(output_dir, 'tabnet_optuna_best_params.xlsx')}")

# 保存优化历史
optuna_history = []
for trial in study.trials:
    if trial.state == optuna.trial.TrialState.COMPLETE:
        params = trial.params.copy()
        params['value'] = trial.value
        optuna_history.append(params)

optuna_history_df = pd.DataFrame(optuna_history)
optuna_history_df.to_excel(os.path.join(output_dir, 'tabnet_optuna_history.xlsx'), index=False)
print(f"Optuna优化历史已保存到 {os.path.join(output_dir, 'tabnet_optuna_history.xlsx')}")

# 绘制优化历史
plt.figure(figsize=(10, 6))
optuna.visualization.matplotlib.plot_optimization_history(study)
plt.savefig(os.path.join(output_dir, 'tabnet_optuna_history.png'))
plt.close()

# 绘制参数重要性
plt.figure(figsize=(12, 8))
optuna.visualization.matplotlib.plot_param_importances(study)
plt.savefig(os.path.join(output_dir, 'tabnet_optuna_param_importances.png'))
plt.close()

# 使用最佳参数训练最终模型
print("\n使用Optuna最佳参数训练最终模型...")
final_model = TabNetRegressor(
    n_d=best_params_optuna['n_d'],
    n_steps=best_params_optuna['n_steps'],
    gamma=best_params_optuna['gamma'],
    n_independent=best_params_optuna['n_independent'],
    n_shared=best_params_optuna['n_shared'],
    lambda_sparse=best_params_optuna['lambda_sparse'],
    momentum=best_params_optuna['momentum'],
    optimizer_fn=torch.optim.Adam,
    optimizer_params=dict(lr=best_params_optuna['learning_rate']),
    scheduler_params={"step_size": 10, "gamma": 0.9},
    scheduler_fn=torch.optim.lr_scheduler.StepLR,
    mask_type='entmax',
    clip_value=best_params_optuna['clip_value'],
    verbose=1
)


# 训练最终模型时手动记录训练历史
class MetricsCallback:
    def __init__(self):
        self.train_rmse = []
        self.valid_rmse = []

    def __call__(self, epoch, metrics):
        self.train_rmse.append(metrics['train_rmse'])
        self.valid_rmse.append(metrics['valid_rmse'])
        return False  # 不提前停止训练


metrics_callback = MetricsCallback()

# 训练模型
final_model.fit(
    X_train_scaled, y_train,
    eval_set=[(X_train_scaled, y_train), (X_val_scaled, y_val)],
    eval_name=['train', 'valid'],
    max_epochs=best_params_optuna['max_epochs'],
    patience=best_params_optuna['patience'],
    batch_size=best_params_optuna['batch_size'],
    virtual_batch_size=best_params_optuna['virtual_batch_size'],
    eval_metric=['rmse'],
    callbacks=[metrics_callback]
)

# 保存模型
model_path = os.path.join(output_dir, 'tabnet_final_model.pkl')
joblib.dump(final_model, model_path)
print(f"最终模型已保存到 {model_path}")

# 使用记录的损失绘制曲线
plt.figure(figsize=(10, 6))
plt.plot(metrics_callback.train_rmse, label='训练集RMSE')
plt.plot(metrics_callback.valid_rmse, label='验证集RMSE')
plt.xlabel('Epoch')
plt.ylabel('RMSE')
plt.title('TabNet训练和验证损失曲线')
plt.legend()
plt.grid(True)
plt.savefig(os.path.join(output_dir, 'tabnet_loss_curve.png'))
plt.close()

# 评估模型
print("\n模型评估:")
train_results = evaluate_model(final_model, X_train_scaled, y_train, "训练集")
val_results = evaluate_model(final_model, X_val_scaled, y_val, "验证集")
test_results = evaluate_model(final_model, X_test_scaled, y_test, "测试集")

# 保存评估结果
results_df = pd.DataFrame([
    {'数据集': '训练集', 'R²': train_results['r2'], 'MAE': train_results['mae'], 'MSE': train_results['mse'],
     'RMSE': train_results['rmse']},
    {'数据集': '验证集', 'R²': val_results['r2'], 'MAE': val_results['mae'], 'MSE': val_results['mse'],
     'RMSE': val_results['rmse']},
    {'数据集': '测试集', 'R²': test_results['r2'], 'MAE': test_results['mae'], 'MSE': test_results['mse'],
     'RMSE': test_results['rmse']}
])

results_df.to_excel(os.path.join(output_dir, 'tabnet_evaluation_metrics.xlsx'), index=False)
print(f"评估指标已保存到 {os.path.join(output_dir, 'tabnet_evaluation_metrics.xlsx')}")


# 保存预测结果
def save_predictions(data, X_scaled, dataset_name):
    # 获取预测值
    y_pred = final_model.predict(X_scaled)

    # 创建结果DataFrame
    result_df = data.copy()
    result_df['预测值'] = y_pred.ravel()  # 确保预测值是一维的
    result_df['残差'] = result_df[target] - result_df['预测值']

    # 保存结果
    output_path = os.path.join(output_dir, f'tabnet_{dataset_name}_predictions.xlsx')
    result_df.to_excel(output_path, index=False)
    print(f"{dataset_name}预测结果已保存到 {output_path}")

    return result_df


# 保存各数据集的预测结果
train_pred_df = save_predictions(train_data, X_train_scaled, "训练集")
val_pred_df = save_predictions(validation_data, X_val_scaled, "验证集")
test_pred_df = save_predictions(test_data, X_test_scaled, "测试集")


# 绘制真实值vs预测值散点图
def plot_actual_vs_predicted(y_true, y_pred, dataset_name):
    plt.figure(figsize=(8, 8))
    plt.scatter(y_true, y_pred, alpha=0.5)
    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')
    plt.xlabel('真实值')
    plt.ylabel('预测值')
    plt.title(f'TabNet {dataset_name} 真实值 vs 预测值')
    plt.grid(True)
    plt.savefig(os.path.join(output_dir, f'tabnet_{dataset_name}_actual_vs_predicted.png'))
    plt.close()


# 为每个数据集绘制散点图
plot_actual_vs_predicted(train_results['y_true'], train_results['y_pred'], "训练集")
plot_actual_vs_predicted(val_results['y_true'], val_results['y_pred'], "验证集")
plot_actual_vs_predicted(test_results['y_true'], test_results['y_pred'], "测试集")

# 汇总粗调和精调的参数对比
params_comparison = pd.DataFrame([
    {'调参方法': '网格搜索粗调', **best_params_grid},
    {'调参方法': 'Optuna精调', **best_params_optuna}
])
params_comparison.to_excel(os.path.join(output_dir, 'tabnet_params_comparison.xlsx'), index=False)
print(f"参数对比已保存到 {os.path.join(output_dir, 'tabnet_params_comparison.xlsx')}")

print("\nTabNet回归模型训练和评估完成！")
print(f"所有结果已保存到目录: {output_dir}")
