import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.model_selection import KFold, GridSearchCV, train_test_split
import os
import time
import joblib
from tqdm import tqdm

# 创建输出目录（如果不存在）
output_dir = "F:\\Machine leaning_SHAP\\PLS"
os.makedirs(output_dir, exist_ok=True)

# 设置中文显示
plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

# 读取统一数据集
print("正在读取数据集...")
data = pd.read_excel("F:\\Machine leaning_SHAP\\数据集.xlsx")
print(f"数据集读取完成! 总共: {data.shape[0]}行")

# 定义特征和目标变量
features = ["TA", "RH", "P", "SP", "SD", "ATM", "PAR", "TS", "shallow_SWC", "deep_SWC"]
target = "NEP"

# 提取特征和目标变量
X = data[features]
y = data[target]

# 划分数据集：训练集21888条，验证集7344条，测试集5856条
print("正在划分数据集...")
# 首先分离出测试集（5856条）
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=5856, random_state=42, shuffle=True
)

# 然后从剩余数据中分离训练集（21888条）和验证集（7344条）
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=7344, random_state=42, shuffle=True
)

print(f"数据集划分完成!")
print(f"训练集: {X_train.shape[0]}行")
print(f"验证集: {X_val.shape[0]}行") 
print(f"测试集: {X_test.shape[0]}行")

# 保存划分后的数据集
train_data = pd.concat([X_train, y_train], axis=1)
val_data = pd.concat([X_val, y_val], axis=1)
test_data = pd.concat([X_test, y_test], axis=1)

train_data.to_excel(os.path.join(output_dir, "训练集.xlsx"), index=False)
val_data.to_excel(os.path.join(output_dir, "验证集.xlsx"), index=False)
test_data.to_excel(os.path.join(output_dir, "测试集.xlsx"), index=False)
print("划分后的数据集已保存!")

# 数据归一化
print("正在进行数据归一化...")
scaler = MinMaxScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)
print("数据归一化完成!")

# 合并训练集和验证集用于交叉验证
X_train_val = np.vstack((X_train_scaled, X_val_scaled))
y_train_val = np.concatenate((y_train.values, y_val.values))

# 定义评估函数
def evaluate_model(y_true, y_pred, dataset_name):
    r2 = r2_score(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    
    print(f"{dataset_name} 评估指标:")
    print(f"R² = {r2:.4f}")
    print(f"MAE = {mae:.4f}")
    print(f"MSE = {mse:.4f}")
    print(f"RMSE = {rmse:.4f}")
    print("\n")
    
    return {
        "R²": r2,
        "MAE": mae,
        "MSE": mse,
        "RMSE": rmse
    }

# 定义网格搜索的参数范围
param_grid = {
    'n_components': range(1, min(11, len(features) + 1))  # 从1到特征数量的组件数
}

# 5折交叉验证
print("\n" + "="*50)
print("开始5折交叉验证...")
start_time = time.time()

kf = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = {
    "R²": [],
    "MAE": [],
    "MSE": [],
    "RMSE": []
}

# 记录每折的最佳组件数
best_n_components_per_fold = []

# 使用tqdm显示进度
for fold, (train_idx, val_idx) in enumerate(tqdm(kf.split(X_train_val), total=5, desc="交叉验证进度")):
    print(f"\n正在训练第 {fold+1} 折...")
    
    # 分割数据
    X_fold_train, X_fold_val = X_train_val[train_idx], X_train_val[val_idx]
    y_fold_train, y_fold_val = y_train_val[train_idx], y_train_val[val_idx]
    
    # 使用网格搜索找到最佳组件数
    print(f"第 {fold+1} 折参数优化:")
    pls = PLSRegression()
    grid_search = GridSearchCV(pls, param_grid, cv=5, scoring='neg_mean_squared_error')
    grid_search.fit(X_fold_train, y_fold_train)
    
    best_n_components = grid_search.best_params_['n_components']
    best_n_components_per_fold.append(best_n_components)
    print(f"最佳组件数: {best_n_components}")
    
    # 使用最佳组件数训练模型
    best_model = PLSRegression(n_components=best_n_components)
    best_model.fit(X_fold_train, y_fold_train)
    
    # 预测并评估
    y_fold_pred = best_model.predict(X_fold_val).flatten()
    fold_metrics = evaluate_model(y_fold_val, y_fold_pred, f"第 {fold+1} 折验证集")
    
    # 保存指标
    for metric in cv_scores.keys():
        cv_scores[metric].append(fold_metrics[metric])

# 计算平均交叉验证分数
print("\n交叉验证平均指标:")
for metric, scores in cv_scores.items():
    print(f"平均 {metric} = {np.mean(scores):.4f} ± {np.std(scores):.4f}")

end_time = time.time()
print(f"交叉验证耗时: {end_time - start_time:.2f}秒")
print("="*50 + "\n")

# 分析每折的最佳组件数
print("\n各折最佳组件数:")
for fold, n_components in enumerate(best_n_components_per_fold):
    print(f"第 {fold+1} 折: {n_components}")

# 选择出现频率最高的组件数作为最终组件数
from collections import Counter
component_counts = Counter(best_n_components_per_fold)
final_n_components = component_counts.most_common(1)[0][0]
print(f"\n最终选择的组件数: {final_n_components}")

# 训练最终模型
print("\n训练最终模型...")
final_model = PLSRegression(n_components=final_n_components)
final_model.fit(X_train_scaled, y_train)
print("最终模型训练完成!")

# 保存模型和选择的组件数
print("正在保存模型...")
joblib.dump(final_model, os.path.join(output_dir, "PLS_最终模型.pkl"))
joblib.dump(scaler, os.path.join(output_dir, "PLS_特征缩放器.pkl"))
joblib.dump(final_n_components, os.path.join(output_dir, "PLS_组件数.pkl"))
print("模型保存完成!")

# 预测
print("\n正在进行预测...")
y_train_pred = final_model.predict(X_train_scaled).flatten()
y_val_pred = final_model.predict(X_val_scaled).flatten()
y_test_pred = final_model.predict(X_test_scaled).flatten()
print("预测完成!")

# 评估模型
print("\n正在评估模型性能...")
train_metrics = evaluate_model(y_train, y_train_pred, "训练集")
val_metrics = evaluate_model(y_val, y_val_pred, "验证集")
test_metrics = evaluate_model(y_test, y_test_pred, "测试集")

# 将评估指标保存到Excel
metrics_df = pd.DataFrame({
    "指标": ["R²", "MAE", "MSE", "RMSE"],
    "训练集": [train_metrics["R²"], train_metrics["MAE"], train_metrics["MSE"], train_metrics["RMSE"]],
    "验证集": [val_metrics["R²"], val_metrics["MAE"], val_metrics["MSE"], val_metrics["RMSE"]],
    "测试集": [test_metrics["R²"], test_metrics["MAE"], test_metrics["MSE"], test_metrics["RMSE"]]
})
metrics_df.to_excel(os.path.join(output_dir, "PLS_评估指标.xlsx"), index=False)
print("评估指标已保存!")

# 保存交叉验证结果
cv_results_df = pd.DataFrame({
    "折数": [f"第{i+1}折" for i in range(5)],
    "R²": cv_scores["R²"],
    "MAE": cv_scores["MAE"],
    "MSE": cv_scores["MSE"],
    "RMSE": cv_scores["RMSE"],
    "最佳组件数": best_n_components_per_fold
})
cv_results_df.to_excel(os.path.join(output_dir, "PLS_交叉验证结果.xlsx"), index=False)

# 绘制实际值与预测值的对比图
def plot_actual_vs_predicted(y_true, y_pred, title, filename):
    plt.figure(figsize=(10, 6))
    plt.scatter(y_true, y_pred, alpha=0.5)
    
    # 添加对角线（理想预测线）
    min_val = min(min(y_true), min(y_pred))
    max_val = max(max(y_true), max(y_pred))
    plt.plot([min_val, max_val], [min_val, max_val], 'r--')
    
    plt.xlabel('实际值')
    plt.ylabel('预测值')
    plt.title(title)
    plt.grid(True)
    plt.savefig(filename, dpi=300, bbox_inches='tight')
    plt.close()

# 绘制实际值与预测值的对比图
print("\n正在绘制实际值与预测值对比图...")
plot_actual_vs_predicted(y_train, y_train_pred, "训练集：实际值 vs 预测值", 
                        os.path.join(output_dir, "PLS_训练集_实际vs预测.png"))
plot_actual_vs_predicted(y_val, y_val_pred, "验证集：实际值 vs 预测值", 
                        os.path.join(output_dir, "PLS_验证集_实际vs预测.png"))
plot_actual_vs_predicted(y_test, y_test_pred, "测试集：实际值 vs 预测值", 
                        os.path.join(output_dir, "PLS_测试集_实际vs预测.png"))
print("对比图绘制完成!")

# 保存预测结果
def save_predictions(data, y_pred, filename):
    # 复制原始数据
    result_df = data.copy()
    # 添加预测列
    result_df['预测值'] = y_pred
    # 添加残差列
    result_df['残差'] = result_df[target] - result_df['预测值']
    # 保存到Excel
    result_df.to_excel(filename, index=False)

# 保存预测结果
print("\n正在保存预测结果...")
save_predictions(train_data, y_train_pred, os.path.join(output_dir, "PLS_训练集_预测结果.xlsx"))
save_predictions(val_data, y_val_pred, os.path.join(output_dir, "PLS_验证集_预测结果.xlsx"))
save_predictions(test_data, y_test_pred, os.path.join(output_dir, "PLS_测试集_预测结果.xlsx"))
print("预测结果保存完成!")

# 特征重要性分析（VIP分数）
print("\n正在进行特征重要性分析...")

# 计算VIP分数
# 计算VIP分数
def vip(model):
    t = model.x_scores_
    w = model.x_weights_
    q = model.y_loadings_
    p, h = w.shape
    
    vips = np.zeros((p,))
    s = np.diag(t.T @ t @ q.T @ q).reshape(h, -1)
    total_s = np.sum(s)
    
    for i in range(p):
        weight = np.array([(w[i, j] / np.linalg.norm(w[:, j]))**2 for j in range(h)])
        # 修复：使用.item()或[0]来提取标量值
        vips[i] = np.sqrt(p * (s.T @ weight).item() / total_s)
    
    return vips

# 计算VIP分数
vip_scores = vip(final_model)

# 创建特征重要性DataFrame
feature_importance_df = pd.DataFrame({
    '特征': features,
    'VIP分数': vip_scores
})

# 按VIP分数排序
feature_importance_df = feature_importance_df.sort_values('VIP分数', ascending=False)

# 保存特征重要性到Excel
feature_importance_df.to_excel(os.path.join(output_dir, "PLS_特征重要性.xlsx"), index=False)

# 绘制特征重要性图
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['特征'], feature_importance_df['VIP分数'])
plt.xlabel('VIP分数')
plt.title('偏最小二乘法 特征重要性 (VIP)')
plt.axvline(x=1.0, color='r', linestyle='--')  # VIP > 1被认为是重要的
plt.tight_layout()
plt.savefig(os.path.join(output_dir, "PLS_特征重要性.png"), dpi=300, bbox_inches='tight')
plt.close()
print("特征重要性分析完成!")

# 输出模型信息
print("\n偏最小二乘法模型信息:")
print(f"组件数: {final_n_components}")
print(f"X权重形状: {final_model.x_weights_.shape}")
print(f"X载荷形状: {final_model.x_loadings_.shape}")
print(f"Y载荷形状: {final_model.y_loadings_.shape}")

# 保存模型信息到文本文件
with open(os.path.join(output_dir, "PLS_模型信息.txt"), "w", encoding="utf-8") as f:
    f.write("偏最小二乘法模型信息:\n")
    f.write(f"数据集划分:\n")
    f.write(f"  训练集: {X_train.shape[0]}条\n")
    f.write(f"  验证集: {X_val.shape[0]}条\n")
    f.write(f"  测试集: {X_test.shape[0]}条\n\n")
    f.write(f"模型参数:\n")
    f.write(f"  组件数: {final_n_components}\n")
    f.write(f"  X权重形状: {final_model.x_weights_.shape}\n")
    f.write(f"  X载荷形状: {final_model.x_loadings_.shape}\n")
    f.write(f"  Y载荷形状: {final_model.y_loadings_.shape}\n\n")
    f.write("重要特征 (VIP > 1.0):\n")
    for _, row in feature_importance_df[feature_importance_df['VIP分数'] > 1.0].iterrows():
        f.write(f"  {row['特征']}: {row['VIP分数']:.4f}\n")

print("\n所有结果已保存到目录: " + output_dir)
print("偏最小二乘法模型训练与评估完成!")
